# PyCline æˆ˜ç•¥å®Œå–„æ–¹æ¡ˆ

åŸºäºå¯¹Clineå®Œæ•´æ¶æ„çš„æ·±å…¥åˆ†æï¼Œåˆ¶å®šPyClineçš„æˆ˜ç•¥æ€§å®Œå–„æ–¹æ¡ˆã€‚

## ğŸ¯ æ ¸å¿ƒå·®è·åˆ†æ

### 1. æ¶æ„å±‚é¢å·®è·

| æ¶æ„å±‚ | Cline | PyClineå½“å‰ | å…³é”®å·®è· |
|--------|-------|-------------|----------|
| **æ§åˆ¶å™¨å±‚** | Controller + TaskManager + StateManager | PyClineå•ä¸€ç±» | ç¼ºå°‘ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸç®¡ç† |
| **å·¥å…·æ‰§è¡Œå±‚** | ToolExecutor + æƒé™æ§åˆ¶ + æ²™ç®± | ç®€å•å·¥å…·è°ƒç”¨ | ç¼ºå°‘å®‰å…¨æœºåˆ¶å’Œæƒé™æ§åˆ¶ |
| **ä¸Šä¸‹æ–‡ç®¡ç†** | æ™ºèƒ½è£å‰ª + ä¼˜å…ˆçº§ç®—æ³• | åŸºç¡€æ–‡ä»¶æ‹¼æ¥ | ç¼ºå°‘æ™ºèƒ½ä¸Šä¸‹æ–‡ä¼˜åŒ– |
| **APIå¤„ç†** | å¤šæ¨¡å‹é€‚é… + æµå¼å¤„ç† | DeepSeekå•ä¸€é›†æˆ | ç¼ºå°‘å¤šæ¨¡å‹æ”¯æŒ |
| **å®‰å…¨æœºåˆ¶** | å¤šå±‚é˜²æŠ¤ + ç”¨æˆ·ç¡®è®¤ | åŸºç¡€å‘½ä»¤æ£€æŸ¥ | ç¼ºå°‘å®Œæ•´å®‰å…¨ä½“ç³» |

### 2. å·¥å…·ç³»ç»Ÿè¯¦ç»†å¯¹æ¯”

#### Clineå·¥å…·æ¸…å• (åŸºäºæºç åˆ†æ)
```
æ–‡ä»¶æ“ä½œç±» (5ä¸ªå·¥å…·):
âœ… read_file - å·²å®ç°
âœ… write_to_file - å·²å®ç° (write_file)
âŒ replace_in_file - ç¼ºå¤± (å…³é”®å·¥å…·)
âœ… list_files - å·²å®ç° (list_directory)
âŒ str_replace_editor - ç¼ºå¤±

ç»ˆç«¯æ‰§è¡Œç±» (1ä¸ªå·¥å…·):
âœ… execute_command - å·²å®ç° (bash)

æµè§ˆå™¨æ§åˆ¶ç±» (1ä¸ªå·¥å…·):
âŒ browser_action - ç¼ºå¤± (é‡è¦åŠŸèƒ½)

æœç´¢å·¥å…·ç±» (1ä¸ªå·¥å…·):
âŒ grep_search - ç¼ºå¤±

MCPæ‰©å±•ç±» (1ä¸ªå·¥å…·):
âŒ use_mcp_tool - ç¼ºå¤±

è®¡ç®—æœºæ§åˆ¶ç±» (1ä¸ªå·¥å…·):
âŒ computer_20241022 - ç¼ºå¤± (æ¡Œé¢æ“ä½œ)
```

**å½“å‰è¦†ç›–ç‡**: 4/10 = 40%

### 3. ç”¨æˆ·äº¤äº’æ¨¡å¼å¯¹æ¯”

#### Clineäº¤äº’æ¨¡å¼
- **Chatæ¨¡å¼**: è¿ç»­å¯¹è¯ï¼Œä¸Šä¸‹æ–‡ä¿æŒ
- **Taskæ¨¡å¼**: å•æ¬¡ä»»åŠ¡æ‰§è¡Œ
- **Planæ¨¡å¼**: å…ˆè§„åˆ’åæ‰§è¡Œ
- **Autoæ¨¡å¼**: è‡ªåŠ¨æ‰§è¡Œï¼Œæœ€å°ç”¨æˆ·å¹²é¢„

#### PyClineå½“å‰äº¤äº’
```python
# åªæœ‰åŸºç¡€çš„ä»»åŠ¡æ‰§è¡Œæ¥å£
result = cline.execute_task("åˆ›å»ºä¸€ä¸ªPythonæ–‡ä»¶")
```

## ğŸš€ ä¸‰é˜¶æ®µæˆ˜ç•¥è§„åˆ’

### Phase 1: æ ¸å¿ƒæ¶æ„é‡æ„ (6å‘¨)
**ç›®æ ‡**: å»ºç«‹ä¸Clineå¯¹ç­‰çš„æ¶æ„åŸºç¡€

#### Week 1-2: æ§åˆ¶å™¨å±‚é‡æ„
```python
# core/controller.py - å‚è€ƒClineçš„Controllerè®¾è®¡
class PyClineController:
    def __init__(self):
        self.task_manager = TaskManager()
        self.state_manager = StateManager()
        self.workspace_tracker = WorkspaceTracker()
        self.auth_service = AuthService()
        
    def init_task(self, task_description: str, **kwargs) -> Task:
        """åˆå§‹åŒ–ä»»åŠ¡ - å¯¹æ ‡Clineçš„initTask"""
        task = self.task_manager.create_task(task_description)
        task.initialize_components()
        return task
        
    def handle_message(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æ¶ˆæ¯ - å¯¹æ ‡Clineçš„handleWebviewMessage"""
        return self.task_manager.process_message(message)
        
    def post_state_update(self):
        """çŠ¶æ€åŒæ­¥ - å¯¹æ ‡Clineçš„postStateToWebview"""
        current_state = self.state_manager.get_current_state()
        # å¹¿æ’­çŠ¶æ€æ›´æ–°

# core/task_manager.py - å‚è€ƒClineçš„Taskç±»
class TaskManager:
    def __init__(self):
        self.current_task: Optional[Task] = None
        self.task_history: List[HistoryItem] = []
        
    def create_task(self, description: str) -> Task:
        """åˆ›å»ºä»»åŠ¡å®ä¾‹"""
        task = Task(
            id=str(uuid.uuid4()),
            description=description,
            tool_executor=ToolExecutor(),
            context_manager=ContextManager(),
            api_handler=ApiHandler(),
            message_handler=MessageStateHandler()
        )
        self.current_task = task
        return task
        
    def execute_task(self, task: Task) -> TaskResult:
        """æ‰§è¡Œä»»åŠ¡ä¸»å¾ªç¯ - å¯¹æ ‡Clineçš„ä»»åŠ¡æ‰§è¡Œé€»è¾‘"""
        while not task.is_complete():
            # 1. æ„å»ºä¸Šä¸‹æ–‡
            context = task.context_manager.build_context()
            
            # 2. è°ƒç”¨AI API
            ai_response = task.api_handler.call_ai(context)
            
            # 3. å¤„ç†å·¥å…·è°ƒç”¨
            if ai_response.has_tool_calls():
                for tool_call in ai_response.tool_calls:
                    result = task.tool_executor.execute(tool_call)
                    task.add_tool_result(result)
            
            # 4. æ›´æ–°çŠ¶æ€
            task.update_state(ai_response)
            
        return task.get_result()
```

#### Week 3-4: å·¥å…·æ‰§è¡Œç³»ç»Ÿé‡æ„
```python
# core/tool_executor.py - å‚è€ƒClineçš„ToolExecutor
class ToolExecutor:
    def __init__(self):
        self.tools: Dict[str, Tool] = {}
        self.security_manager = SecurityManager()
        self.permission_manager = PermissionManager()
        self.tool_cache = ToolCache()
        
    def execute_tool(self, tool_name: str, parameters: Dict[str, Any]) -> ToolResult:
        """æ‰§è¡Œå·¥å…· - å¯¹æ ‡Clineçš„å·¥å…·æ‰§è¡Œæµç¨‹"""
        
        # 1. å‚æ•°éªŒè¯
        validation_result = self._validate_parameters(tool_name, parameters)
        if not validation_result.valid:
            return ToolResult.error(validation_result.error)
        
        # 2. å®‰å…¨æ£€æŸ¥
        security_result = self.security_manager.validate_operation(
            tool_name, parameters
        )
        if not security_result.is_safe:
            return ToolResult.denied(security_result.reason)
            
        # 3. æƒé™æ£€æŸ¥
        if not self.permission_manager.has_permission(tool_name, parameters):
            # è¯·æ±‚ç”¨æˆ·ç¡®è®¤
            if not self._request_user_approval(tool_name, parameters):
                return ToolResult.denied("ç”¨æˆ·æ‹’ç»æ‰§è¡Œ")
                
        # 4. ç¼“å­˜æ£€æŸ¥
        cache_key = self.tool_cache.get_cache_key(tool_name, parameters)
        if self.tool_cache.has_valid_cache(cache_key):
            return self.tool_cache.get_cached_result(cache_key)
        
        # 5. æ‰§è¡Œå·¥å…·
        tool = self.tools[tool_name]
        try:
            start_time = time.time()
            result = tool.execute(**parameters)
            execution_time = time.time() - start_time
            
            # 6. ç¼“å­˜ç»“æœ
            tool_result = ToolResult.success(result)
            self.tool_cache.cache_result(cache_key, tool_result)
            
            # 7. è®°å½•ç»Ÿè®¡
            self._record_tool_usage(tool_name, execution_time, True)
            
            return tool_result
            
        except Exception as e:
            self._record_tool_usage(tool_name, 0, False)
            return ToolResult.error(str(e))
            
    def _request_user_approval(self, tool_name: str, parameters: Dict[str, Any]) -> bool:
        """ç”¨æˆ·ç¡®è®¤æœºåˆ¶ - å¯¹æ ‡Clineçš„ç”¨æˆ·ç¡®è®¤"""
        risk_level = self._assess_risk(tool_name, parameters)
        
        if risk_level == RiskLevel.LOW:
            return True  # è‡ªåŠ¨æ‰¹å‡†ä½é£é™©æ“ä½œ
            
        # æ˜¾ç¤ºç¡®è®¤å¯¹è¯æ¡†
        return self._show_confirmation_dialog(tool_name, parameters, risk_level)
        
    def _assess_risk(self, tool_name: str, parameters: Dict[str, Any]) -> RiskLevel:
        """é£é™©è¯„ä¼° - å¯¹æ ‡Clineçš„é£é™©è¯„ä¼°ç®—æ³•"""
        if tool_name == "execute_command":
            command = parameters.get("command", "")
            if self._is_dangerous_command(command):
                return RiskLevel.HIGH
            elif self._is_system_command(command):
                return RiskLevel.MEDIUM
            else:
                return RiskLevel.LOW
                
        elif tool_name in ["write_file", "replace_in_file"]:
            file_path = parameters.get("file_path", "")
            if self._is_system_file(file_path):
                return RiskLevel.HIGH
            else:
                return RiskLevel.LOW
                
        return RiskLevel.LOW

# core/security_manager.py - å‚è€ƒClineçš„å®‰å…¨æœºåˆ¶
class SecurityManager:
    def __init__(self):
        self.security_policies = self._load_security_policies()
        self.dangerous_commands = [
            'rm -rf /', 'format', 'del /q', ':(){ :|:& };:',
            'sudo rm', 'dd if=', 'mkfs', 'fdisk'
        ]
        
    def validate_operation(self, tool_name: str, parameters: Dict[str, Any]) -> SecurityResult:
        """å®‰å…¨éªŒè¯ - å¯¹æ ‡Clineçš„å®‰å…¨æ£€æŸ¥"""
        
        # 1. å‘½ä»¤å®‰å…¨æ£€æŸ¥
        if tool_name == "execute_command":
            command = parameters.get("command", "")
            if self._is_dangerous_command(command):
                return SecurityResult.unsafe(f"å±é™©å‘½ä»¤: {command}")
                
        # 2. æ–‡ä»¶è·¯å¾„éªŒè¯
        if "file_path" in parameters:
            file_path = parameters["file_path"]
            if not self._is_safe_path(file_path):
                return SecurityResult.unsafe(f"ä¸å®‰å…¨çš„æ–‡ä»¶è·¯å¾„: {file_path}")
                
        # 3. èµ„æºé™åˆ¶æ£€æŸ¥
        if not self._check_resource_limits():
            return SecurityResult.unsafe("èµ„æºä½¿ç”¨è¶…é™")
            
        return SecurityResult.safe()
        
    def _is_dangerous_command(self, command: str) -> bool:
        """å±é™©å‘½ä»¤æ£€æµ‹"""
        command_lower = command.lower().strip()
        return any(dangerous in command_lower for dangerous in self.dangerous_commands)
        
    def _is_safe_path(self, file_path: str) -> bool:
        """æ–‡ä»¶è·¯å¾„å®‰å…¨æ£€æŸ¥"""
        # é˜²æ­¢ç›®å½•éå†æ”»å‡»
        normalized_path = os.path.normpath(file_path)
        if '..' in normalized_path:
            return False
            
        # æ£€æŸ¥ç³»ç»Ÿå…³é”®ç›®å½•
        system_paths = ['/etc', '/sys', '/proc', '/dev', 'C:\\Windows', 'C:\\System32']
        for sys_path in system_paths:
            if normalized_path.startswith(sys_path):
                return False
                
        return True
```

#### Week 5-6: ä¸Šä¸‹æ–‡ç®¡ç†ç³»ç»Ÿ
```python
# core/context_manager.py - å‚è€ƒClineçš„ä¸Šä¸‹æ–‡ç®¡ç†
class ContextManager:
    def __init__(self):
        self.file_tracker = FileContextTracker()
        self.model_tracker = ModelContextTracker()
        self.context_window = ContextWindowUtils()
        self.max_context_tokens = 100000
        
    def build_context(self, task_description: str, workspace_path: str) -> Context:
        """æ„å»ºæ™ºèƒ½ä¸Šä¸‹æ–‡ - å¯¹æ ‡Clineçš„ä¸Šä¸‹æ–‡æ„å»º"""
        
        # 1. åˆ†æä»»åŠ¡éœ€æ±‚
        task_analysis = self._analyze_task_requirements(task_description)
        
        # 2. å‘ç°ç›¸å…³æ–‡ä»¶
        relevant_files = self._discover_relevant_files(
            task_analysis, workspace_path
        )
        
        # 3. è®¡ç®—æ–‡ä»¶ä¼˜å…ˆçº§
        prioritized_files = self._prioritize_files(relevant_files, task_analysis)
        
        # 4. ä¼˜åŒ–ä¸Šä¸‹æ–‡çª—å£
        optimized_context = self.context_window.optimize(
            prioritized_files, task_analysis, self.max_context_tokens
        )
        
        return optimized_context
        
    def _analyze_task_requirements(self, task_description: str) -> TaskAnalysis:
        """ä»»åŠ¡éœ€æ±‚åˆ†æ"""
        # ä½¿ç”¨NLPæŠ€æœ¯åˆ†æä»»åŠ¡æè¿°
        keywords = self._extract_keywords(task_description)
        file_types = self._predict_file_types(task_description)
        complexity = self._assess_task_complexity(task_description)
        
        return TaskAnalysis(
            description=task_description,
            keywords=keywords,
            file_types=file_types,
            complexity=complexity
        )
        
    def _discover_relevant_files(self, task_analysis: TaskAnalysis, workspace: str) -> List[FileInfo]:
        """æ™ºèƒ½æ–‡ä»¶å‘ç° - å¯¹æ ‡Clineçš„æ–‡ä»¶å‘ç°ç®—æ³•"""
        
        relevant_files = []
        
        # 1. åŸºäºå…³é”®è¯æœç´¢
        for keyword in task_analysis.keywords:
            matches = self._search_files_by_keyword(keyword, workspace)
            relevant_files.extend(matches)
            
        # 2. åŸºäºæ–‡ä»¶ç±»å‹è¿‡æ»¤
        type_filtered = [f for f in relevant_files if f.file_type in task_analysis.file_types]
        
        # 3. åŸºäºä¾èµ–å…³ç³»æ‰©å±•
        dependency_expanded = self._expand_by_dependencies(type_filtered, workspace)
        
        # 4. å»é‡å’Œæ’åº
        unique_files = self._deduplicate_files(dependency_expanded)
        
        return unique_files
        
    def _prioritize_files(self, files: List[FileInfo], task_analysis: TaskAnalysis) -> List[FileInfo]:
        """æ–‡ä»¶ä¼˜å…ˆçº§è®¡ç®— - å¯¹æ ‡Clineçš„ä¼˜å…ˆçº§ç®—æ³•"""
        
        for file_info in files:
            score = 0
            
            # å…³é”®è¯åŒ¹é…å¾—åˆ† (40%)
            keyword_score = self._calculate_keyword_score(file_info, task_analysis.keywords)
            score += keyword_score * 0.4
            
            # æ–‡ä»¶ç±»å‹å¾—åˆ† (30%)
            type_score = self._calculate_type_score(file_info, task_analysis.file_types)
            score += type_score * 0.3
            
            # æœ€è¿‘ä¿®æ”¹å¾—åˆ† (20%)
            recency_score = self._calculate_recency_score(file_info)
            score += recency_score * 0.2
            
            # æ–‡ä»¶å¤§å°å¾—åˆ† (10%) - å°æ–‡ä»¶ä¼˜å…ˆ
            size_score = self._calculate_size_score(file_info)
            score += size_score * 0.1
            
            file_info.priority_score = score
            
        return sorted(files, key=lambda f: f.priority_score, reverse=True)

# core/context_window.py - å‚è€ƒClineçš„ä¸Šä¸‹æ–‡çª—å£ç®¡ç†
class ContextWindowUtils:
    def __init__(self):
        self.token_counter = TokenCounter()
        
    def optimize(self, files: List[FileInfo], task_analysis: TaskAnalysis, max_tokens: int) -> Context:
        """ä¸Šä¸‹æ–‡çª—å£ä¼˜åŒ– - å¯¹æ ‡Clineçš„ä¸Šä¸‹æ–‡ä¼˜åŒ–ç®—æ³•"""
        
        context = Context()
        current_tokens = 0
        
        # 1. æ·»åŠ ä»»åŠ¡æè¿° (æœ€é«˜ä¼˜å…ˆçº§)
        task_tokens = self.token_counter.count(task_analysis.description)
        context.add_task_description(task_analysis.description)
        current_tokens += task_tokens
        
        # 2. é¢„ç•™å·¥å…·å®šä¹‰ç©ºé—´
        tool_tokens = self._estimate_tool_tokens()
        available_tokens = max_tokens - current_tokens - tool_tokens
        
        # 3. æŒ‰ä¼˜å…ˆçº§æ·»åŠ æ–‡ä»¶
        for file_info in files:
            file_tokens = self.token_counter.count(file_info.content)
            
            if current_tokens + file_tokens <= available_tokens:
                context.add_file(file_info)
                current_tokens += file_tokens
            else:
                # å°è¯•å‹ç¼©æ–‡ä»¶å†…å®¹
                remaining_tokens = available_tokens - current_tokens
                compressed_content = self._compress_file_content(
                    file_info, remaining_tokens
                )
                if compressed_content:
                    context.add_file(FileInfo(
                        path=file_info.path,
                        content=compressed_content,
                        is_compressed=True
                    ))
                    break
                    
        return context
        
    def _compress_file_content(self, file_info: FileInfo, available_tokens: int) -> Optional[str]:
        """æ–‡ä»¶å†…å®¹å‹ç¼© - å¯¹æ ‡Clineçš„å†…å®¹å‹ç¼©ç­–ç•¥"""
        
        if available_tokens < 100:  # ç©ºé—´å¤ªå°ï¼Œæ”¾å¼ƒ
            return None
            
        if file_info.file_type == FileType.CODE:
            # ä¿ç•™å‡½æ•°ç­¾åã€ç±»å®šä¹‰ã€é‡è¦æ³¨é‡Š
            return self._compress_code_file(file_info.content, available_tokens)
        elif file_info.file_type == FileType.CONFIG:
            # ä¿ç•™å…³é”®é…ç½®é¡¹
            return self._compress_config_file(file_info.content, available_tokens)
        elif file_info.file_type == FileType.MARKDOWN:
            # ä¿ç•™æ ‡é¢˜å’Œé‡è¦æ®µè½
            return self._compress_markdown_file(file_info.content, available_tokens)
        else:
            # ç®€å•æˆªå–
            return self._truncate_content(file_info.content, available_tokens)
            
    def _compress_code_file(self, content: str, max_tokens: int) -> str:
        """ä»£ç æ–‡ä»¶å‹ç¼©"""
        lines = content.split('\n')
        important_lines = []
        
        for line in lines:
            stripped = line.strip()
            # ä¿ç•™å‡½æ•°å®šä¹‰ã€ç±»å®šä¹‰ã€å¯¼å…¥è¯­å¥ã€é‡è¦æ³¨é‡Š
            if (stripped.startswith(('def ', 'class ', 'import ', 'from ')) or
                stripped.startswith('#') and len(stripped) > 10):
                important_lines.append(line)
            elif len(stripped) > 0 and not stripped.startswith('#'):
                # ä¿ç•™éç©ºçš„ä»£ç è¡Œï¼Œä½†å¯èƒ½éœ€è¦æˆªæ–­
                if self.token_counter.count('\n'.join(important_lines + [line])) < max_tokens:
                    important_lines.append(line)
                else:
                    break
                    
        return '\n'.join(important_lines)
```

### Phase 2: å·¥å…·ç³»ç»Ÿæ‰©å±• (4å‘¨)
**ç›®æ ‡**: å®ç°Cline 80%çš„å·¥å…·åŠŸèƒ½

#### Week 7-8: æ ¸å¿ƒå·¥å…·å®ç°
```python
# tools/advanced_file_tools.py - å¯¹æ ‡Clineçš„æ–‡ä»¶å·¥å…·
@tool
def replace_in_file(file_path: str, old_str: str, new_str: str, occurrence: int = -1) -> str:
    """æ–‡ä»¶å†…å®¹æ›¿æ¢ - å¯¹æ ‡Clineçš„replace_in_file"""
    if not os.path.exists(file_path):
        return f"é”™è¯¯ï¼šæ–‡ä»¶ {file_path} ä¸å­˜åœ¨"
        
    # åˆ›å»ºå¤‡ä»½
    backup_path = f"{file_path}.backup.{int(time.time())}"
    shutil.copy2(file_path, backup_path)
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        if occurrence == -1:
            # æ›¿æ¢æ‰€æœ‰å‡ºç°
            new_content = content.replace(old_str, new_str)
            count = content.count(old_str)
        else:
            # æ›¿æ¢æŒ‡å®šå‡ºç°æ¬¡æ•°
            parts = content.split(old_str)
            if len(parts) > occurrence:
                new_content = old_str.join(parts[:occurrence]) + new_str + old_str.join(parts[occurrence+1:])
                count = 1
            else:
                new_content = content
                count = 0
                
        if count > 0:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(new_content)
                
            # ç”Ÿæˆå·®å¼‚æŠ¥å‘Š
            diff = self._generate_diff(content, new_content)
            return f"æˆåŠŸæ›¿æ¢ {count} å¤„å†…å®¹:\n{diff}"
        else:
            # åˆ é™¤å¤‡ä»½
            os.remove(backup_path)
            return "æœªæ‰¾åˆ°è¦æ›¿æ¢çš„å†…å®¹"
            
    except Exception as e:
        # æ¢å¤å¤‡ä»½
        if os.path.exists(backup_path):
            shutil.copy2(backup_path, file_path)
            os.remove(backup_path)
        return f"æ›¿æ¢å¤±è´¥: {str(e)}"

@tool  
def str_replace_editor(file_path: str, old_str: str, new_str: str) -> str:
    """å­—ç¬¦ä¸²æ›¿æ¢ç¼–è¾‘å™¨ - å¯¹æ ‡Clineçš„str_replace_editor"""
    if not os.path.exists(file_path):
        return f"é”™è¯¯ï¼šæ–‡ä»¶ {file_path} ä¸å­˜åœ¨"
        
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
        
    # ç²¾ç¡®åŒ¹é…å¹¶æ›¿æ¢
    if old_str in content:
        new_content = content.replace(old_str, new_str, 1)  # åªæ›¿æ¢ç¬¬ä¸€ä¸ªåŒ¹é…
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
            
        # æ˜¾ç¤ºå·®å¼‚
        diff = self._generate_diff(content, new_content)
        return f"æ–‡ä»¶å·²æ›´æ–°:\n{diff}"
    else:
        # æä¾›ç›¸ä¼¼å†…å®¹å»ºè®®
        suggestions = self._find_similar_content(content, old_str)
        if suggestions:
            return f"æœªæ‰¾åˆ°å®Œå…¨åŒ¹é…çš„å†…å®¹ã€‚ç›¸ä¼¼å†…å®¹:\n" + "\n".join(suggestions[:3])
        else:
            return "æœªæ‰¾åˆ°è¦æ›¿æ¢çš„å†…å®¹"

# tools/search_tools.py - å¯¹æ ‡Clineçš„æœç´¢å·¥å…·
@tool
def grep_search(pattern: str, directory: str = ".", file_pattern: str = "*", 
                max_results: int = 50) -> str:
    """æ–‡ä»¶å†…å®¹æœç´¢ - å¯¹æ ‡Clineçš„grep_search"""
    import re
    import fnmatch
    
    matches = []
    pattern_regex = re.compile(pattern, re.IGNORECASE | re.MULTILINE)
    
    for root, dirs, files in os.walk(directory):
        # è·³è¿‡å¸¸è§çš„å¿½ç•¥ç›®å½•
        dirs[:] = [d for d in dirs if d not in [
            '.git', 'node_modules', '__pycache__', '.venv', 'venv',
            'build', 'dist', '.next', '.nuxt'
        ]]
        
        for file in files:
            if fnmatch.fnmatch(file, file_pattern):
                file_path = os.path.join(root, file)
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                        
                    for line_num, line in enumerate(content.split('\n'), 1):
                        if pattern_regex.search(line):
                            # æä¾›ä¸Šä¸‹æ–‡è¡Œ
                            context_lines = content.split('\n')
                            start_line = max(0, line_num - 2)
                            end_line = min(len(context_lines), line_num + 1)
                            context = '\n'.join(f"{i+1:4d}: {context_lines[i]}" 
                                              for i in range(start_line, end_line))
                            
                            matches.append(f"\n{file_path}:{line_num}:\n{context}")
                            
                            if len(matches) >= max_results:
                                break
                                
                except Exception:
                    continue
                    
                if len(matches) >= max_results:
                    break
                    
    if matches:
        result = f"æœç´¢ç»“æœ (æ¨¡å¼: {pattern}, é™åˆ¶: {max_results}):\n"
        result += "\n".join(matches)
        if len(matches) >= max_results:
            result += f"\n\næ³¨æ„: ç»“æœå·²é™åˆ¶ä¸º {max_results} æ¡ï¼Œå¯èƒ½è¿˜æœ‰æ›´å¤šåŒ¹é…"
        return result
    else:
        return f"æœªæ‰¾åˆ°åŒ¹é… '{pattern}' çš„å†…å®¹"

# tools/browser_tools.py - å¯¹æ ‡Clineçš„æµè§ˆå™¨å·¥å…·
@tool
def browser_action(action: str, **kwargs) -> str:
    """æµè§ˆå™¨æ“ä½œ - å¯¹æ ‡Clineçš„browser_action"""
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    
    # å…¨å±€æµè§ˆå™¨å®ä¾‹ç®¡ç†
    if not hasattr(browser_action, 'driver'):
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--window-size=1920,1080')
        browser_action.driver = webdriver.Chrome(options=chrome_options)
    
    driver = browser_action.driver
    wait = WebDriverWait(driver, 10)
    
    try:
        if action == "launch":
            url = kwargs.get("url")
            driver.get(url)
            title = driver.title
            return f"å·²å¯¼èˆªåˆ°: {url}\né¡µé¢æ ‡é¢˜: {title}"
            
        elif action == "click":
            selector = kwargs.get("selector")
            element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, selector)))
            element.click()
            return f"å·²ç‚¹å‡»å…ƒç´ : {selector}"
            
        elif action == "type":
            selector = kwargs.get("selector")
            text = kwargs.get("text")
            element = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, selector)))
            element.clear()
            element.send_keys(text)
            return f"å·²è¾“å…¥æ–‡æœ¬åˆ°: {selector}"
            
        elif action == "scroll":
            direction = kwargs.get("direction", "down")
            pixels = kwargs.get("pixels", 500)
            if direction == "down":
                driver.execute_script(f"window.scrollBy(0, {pixels});")
            else:
                driver.execute_script(f"window.scrollBy(0, -{pixels});")
            return f"å·²æ»šåŠ¨ {direction} {pixels} åƒç´ "
            
        elif action == "screenshot":
            screenshot_path = kwargs.get("path", f"screenshot_{int(time.time())}.png")
            driver.save_screenshot(screenshot_path)
            return f"æˆªå›¾å·²ä¿å­˜åˆ°: {screenshot_path}"
            
        elif action == "get_text":
            selector = kwargs.get("selector")
            element = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, selector)))
            return f"å…ƒç´ æ–‡æœ¬: {element.text}"
            
        elif action == "get_page_source":
            return f"é¡µé¢æºç :\n{driver.page_source[:2000]}..."  # é™åˆ¶é•¿åº¦
            
        elif action == "close":
            driver.quit()
            delattr(browser_action, 'driver')
            return "æµè§ˆå™¨å·²å…³é—­"
            
        else:
            return f"ä¸æ”¯æŒçš„æ“ä½œ: {action}\næ”¯æŒçš„æ“ä½œ: launch, click, type, scroll, screenshot, get_text, get_page_source, close"
            
    except Exception as e:
        return f"æµè§ˆå™¨æ“ä½œå¤±è´¥: {str(e)}"
```

#### Week 9-10: MCPé›†æˆå’Œé«˜çº§å·¥å…·
```python
# tools/mcp_tools.py - å¯¹æ ‡Clineçš„MCPå·¥å…·
@tool
def use_mcp_tool(server_name: str, tool_name: str, arguments: Dict[str, Any]) -> str:
    """MCPå·¥å…·è°ƒç”¨ - å¯¹æ ‡Clineçš„use_mcp_tool"""
    
    mcp_hub = McpHub.get_instance()
    
    # 1. æ£€æŸ¥æœåŠ¡å™¨è¿æ¥
    if not mcp_hub.is_server_connected(server_name):
        # å°è¯•è‡ªåŠ¨è¿æ¥
        if not mcp_hub.auto_connect_server(server_name):
            return f"é”™è¯¯ï¼šæ— æ³•è¿æ¥åˆ°MCPæœåŠ¡å™¨ {server_name}"
        
    # 2. éªŒè¯å·¥å…·å­˜åœ¨
    available_tools = mcp_hub.get_server_tools(server_name)
    if tool_name not in available_tools:
        tools_list = ", ".join(available_tools.keys())
        return f"é”™è¯¯ï¼šå·¥å…· {tool_name} åœ¨æœåŠ¡å™¨ {server_name} ä¸­ä¸å­˜åœ¨\nå¯ç”¨å·¥å…·: {tools_list}"
        
    # 3. éªŒè¯å‚æ•°
    tool_schema = available_tools[tool_name]
    validation_result = mcp_hub.validate_arguments(tool_schema, arguments)
    if not validation_result.valid:
        return f"å‚æ•°éªŒè¯å¤±è´¥: {validation_result.error}"
        
    # 4. æ‰§è¡Œå·¥å…·
    try:
        result = mcp_hub.call_tool(server_name, tool_name, arguments)
        return f"MCPå·¥å…·æ‰§è¡ŒæˆåŠŸ:\n{result}"
    except Exception as e:
        return f"MCPå·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"

# core/mcp_hub.py - å‚è€ƒClineçš„Mc
