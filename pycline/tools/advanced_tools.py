"""é«˜çº§å·¥å…·å®ç° - replace_in_file, str_replace_editor, grep_search"""

import os
import re
import shutil
import time
import fnmatch
import difflib
from typing import List, Optional
from langchain_core.tools import tool


@tool
def replace_in_file(file_path: str, old_str: str, new_str: str, occurrence: int = -1) -> str:
    """æ–‡ä»¶å†…å®¹æ›¿æ¢å·¥å…·
    
    Args:
        file_path: è¦ä¿®æ”¹çš„æ–‡ä»¶è·¯å¾„
        old_str: è¦æ›¿æ¢çš„åŸå§‹å­—ç¬¦ä¸²
        new_str: æ›¿æ¢åçš„æ–°å­—ç¬¦ä¸²
        occurrence: æ›¿æ¢ç¬¬å‡ ä¸ªåŒ¹é…é¡¹ï¼Œ-1è¡¨ç¤ºæ›¿æ¢æ‰€æœ‰
    """
    if not os.path.exists(file_path):
        return f"é”™è¯¯ï¼šæ–‡ä»¶ {file_path} ä¸å­˜åœ¨"
        
    # åˆ›å»ºå¤‡ä»½
    backup_path = f"{file_path}.backup.{int(time.time())}"
    shutil.copy2(file_path, backup_path)
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
        
    original_content = content
    
    if occurrence == -1:
        # æ›¿æ¢æ‰€æœ‰å‡ºç°
        new_content = content.replace(old_str, new_str)
        count = content.count(old_str)
    else:
        # æ›¿æ¢æŒ‡å®šå‡ºç°æ¬¡æ•°
        parts = content.split(old_str)
        if len(parts) > occurrence:
            new_content = old_str.join(parts[:occurrence]) + new_str + old_str.join(parts[occurrence+1:])
            count = 1
        else:
            new_content = content
            count = 0
            
    if count > 0:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
            
        # ç”Ÿæˆå·®å¼‚æŠ¥å‘Š
        diff_lines = list(difflib.unified_diff(
            original_content.splitlines(keepends=True),
            new_content.splitlines(keepends=True),
            fromfile=f"{file_path} (åŸå§‹)",
            tofile=f"{file_path} (ä¿®æ”¹å)",
            lineterm=""
        ))
        
        diff_output = "".join(diff_lines[:20])  # é™åˆ¶å·®å¼‚è¾“å‡ºé•¿åº¦
        if len(diff_lines) > 20:
            diff_output += "\n... (å·®å¼‚è¿‡é•¿ï¼Œå·²æˆªæ–­)"
            
        return f"æˆåŠŸæ›¿æ¢ {count} å¤„å†…å®¹\n\nå·®å¼‚é¢„è§ˆ:\n{diff_output}"
    else:
        # åˆ é™¤å¤‡ä»½
        os.remove(backup_path)
        return f"æœªæ‰¾åˆ°è¦æ›¿æ¢çš„å†…å®¹: '{old_str}'"


@tool  
def str_replace_editor(file_path: str, old_str: str, new_str: str) -> str:
    """ç²¾ç¡®å­—ç¬¦ä¸²æ›¿æ¢ç¼–è¾‘å™¨
    
    Args:
        file_path: è¦ç¼–è¾‘çš„æ–‡ä»¶è·¯å¾„
        old_str: è¦æ›¿æ¢çš„ç²¾ç¡®å­—ç¬¦ä¸²ï¼ˆæ”¯æŒå¤šè¡Œï¼‰
        new_str: æ›¿æ¢åçš„æ–°å­—ç¬¦ä¸²
    """
    if not os.path.exists(file_path):
        return f"é”™è¯¯ï¼šæ–‡ä»¶ {file_path} ä¸å­˜åœ¨"
        
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
        
    # ç²¾ç¡®åŒ¹é…å¹¶æ›¿æ¢ï¼ˆåªæ›¿æ¢ç¬¬ä¸€ä¸ªåŒ¹é…ï¼‰
    if old_str in content:
        new_content = content.replace(old_str, new_str, 1)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
            
        # ç”Ÿæˆå·®å¼‚æŠ¥å‘Š
        diff_lines = list(difflib.unified_diff(
            content.splitlines(keepends=True),
            new_content.splitlines(keepends=True),
            fromfile=f"{file_path} (åŸå§‹)",
            tofile=f"{file_path} (ä¿®æ”¹å)",
            lineterm=""
        ))
        
        diff_output = "".join(diff_lines[:15])
        if len(diff_lines) > 15:
            diff_output += "\n... (å·®å¼‚è¿‡é•¿ï¼Œå·²æˆªæ–­)"
            
        return f"æ–‡ä»¶å·²æˆåŠŸæ›´æ–°\n\nå·®å¼‚é¢„è§ˆ:\n{diff_output}"
    else:
        # æä¾›ç›¸ä¼¼å†…å®¹å»ºè®®
        suggestions = _find_similar_content(content, old_str)
        if suggestions:
            return f"æœªæ‰¾åˆ°å®Œå…¨åŒ¹é…çš„å†…å®¹ã€‚\n\nç›¸ä¼¼å†…å®¹å»ºè®®:\n" + "\n".join(f"{i+1}. {s}" for i, s in enumerate(suggestions[:3]))
        else:
            return f"æœªæ‰¾åˆ°è¦æ›¿æ¢çš„å†…å®¹: '{old_str[:100]}...'" if len(old_str) > 100 else f"æœªæ‰¾åˆ°è¦æ›¿æ¢çš„å†…å®¹: '{old_str}'"


@tool
def grep_search(pattern: str, directory: str = ".", file_pattern: str = "*", 
                max_results: int = 50, include_context: bool = True) -> str:
    """æ–‡ä»¶å†…å®¹æœç´¢å·¥å…·
    
    Args:
        pattern: æœç´¢çš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        directory: æœç´¢ç›®å½•
        file_pattern: æ–‡ä»¶åæ¨¡å¼ï¼ˆå¦‚ *.pyï¼‰
        max_results: æœ€å¤§ç»“æœæ•°é‡
        include_context: æ˜¯å¦åŒ…å«ä¸Šä¸‹æ–‡è¡Œ
    """
    matches = []
    pattern_regex = re.compile(pattern, re.IGNORECASE | re.MULTILINE)
    
    # å¿½ç•¥çš„ç›®å½•
    ignore_dirs = {
        '.git', 'node_modules', '__pycache__', '.venv', 'venv',
        'build', 'dist', '.next', '.nuxt', 'target', 'bin', 'obj',
        '.pytest_cache', '.mypy_cache', '.tox'
    }
    
    for root, dirs, files in os.walk(directory):
        # è¿‡æ»¤å¿½ç•¥çš„ç›®å½•
        dirs[:] = [d for d in dirs if d not in ignore_dirs]
        
        for file in files:
            if fnmatch.fnmatch(file, file_pattern):
                file_path = os.path.join(root, file)
                
                # è·³è¿‡äºŒè¿›åˆ¶æ–‡ä»¶
                if _is_binary_file(file_path):
                    continue
                    
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                    
                lines = content.split('\n')
                for line_num, line in enumerate(lines, 1):
                    if pattern_regex.search(line):
                        if include_context:
                            # æä¾›ä¸Šä¸‹æ–‡è¡Œ
                            start_line = max(0, line_num - 2)
                            end_line = min(len(lines), line_num + 1)
                            context_lines = []
                            
                            for i in range(start_line, end_line):
                                prefix = ">>> " if i == line_num - 1 else "    "
                                context_lines.append(f"{prefix}{i+1:4d}: {lines[i]}")
                            
                            context = '\n'.join(context_lines)
                            matches.append(f"\nğŸ“ {file_path}:{line_num}\n{context}")
                        else:
                            matches.append(f"{file_path}:{line_num}: {line.strip()}")
                        
                        if len(matches) >= max_results:
                            break
                            
                if len(matches) >= max_results:
                    break
                    
    if matches:
        result = f"ğŸ” æœç´¢ç»“æœ (æ¨¡å¼: '{pattern}', æ–‡ä»¶: {file_pattern}):\n"
        result += "\n".join(matches)
        if len(matches) >= max_results:
            result += f"\n\nâš ï¸  ç»“æœå·²é™åˆ¶ä¸º {max_results} æ¡ï¼Œå¯èƒ½è¿˜æœ‰æ›´å¤šåŒ¹é…"
        return result
    else:
        return f"âŒ æœªæ‰¾åˆ°åŒ¹é… '{pattern}' çš„å†…å®¹"


def _find_similar_content(content: str, target: str, max_suggestions: int = 3) -> List[str]:
    """æŸ¥æ‰¾ç›¸ä¼¼å†…å®¹"""
    lines = content.split('\n')
    target_lines = target.split('\n')
    
    if len(target_lines) == 1:
        # å•è¡ŒåŒ¹é…
        target_line = target_lines[0].strip()
        similar_lines = []
        
        for i, line in enumerate(lines):
            line_stripped = line.strip()
            if line_stripped and target_line:
                # è®¡ç®—ç›¸ä¼¼åº¦
                similarity = difflib.SequenceMatcher(None, target_line.lower(), line_stripped.lower()).ratio()
                if similarity > 0.6:  # ç›¸ä¼¼åº¦é˜ˆå€¼
                    similar_lines.append((similarity, f"ç¬¬{i+1}è¡Œ: {line.strip()}"))
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similar_lines.sort(key=lambda x: x[0], reverse=True)
        return [line[1] for line in similar_lines[:max_suggestions]]
    else:
        # å¤šè¡ŒåŒ¹é…
        suggestions = []
        
        # æŸ¥æ‰¾åŒ…å«ç›®æ ‡ç¬¬ä¸€è¡Œçš„ä½ç½®
        first_line = target_lines[0].strip()
        for i, line in enumerate(lines):
            if first_line.lower() in line.lower():
                # æå–å‘¨å›´å‡ è¡Œä½œä¸ºå»ºè®®
                start = max(0, i - 1)
                end = min(len(lines), i + len(target_lines) + 1)
                suggestion = '\n'.join(lines[start:end])
                suggestions.append(f"ç¬¬{i+1}è¡Œé™„è¿‘:\n{suggestion}")
                
        return suggestions[:max_suggestions]


def _is_binary_file(file_path: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶"""
    with open(file_path, 'rb') as f:
        chunk = f.read(1024)
        return b'\0' in chunk


class AdvancedToolManager:
    """
    é«˜çº§å·¥å…·ç®¡ç†å™¨ - å·²åºŸå¼ƒï¼Œç”±AIç›´æ¥å†³å®šå·¥å…·ä½¿ç”¨
    
    æ³¨æ„ï¼šè¿™ä¸ªç±»å·²ç»ä¸å†ä½¿ç”¨åŸºäºè§„åˆ™çš„å·¥å…·é€‰æ‹©
    ç°åœ¨ç”±LangGraphProviderçš„AIç›´æ¥å†³å®šä½¿ç”¨å“ªäº›å·¥å…·
    """
    
    def __init__(self):
        self.tools = {
            'replace_in_file': replace_in_file,
            'str_replace_editor': str_replace_editor,
            'grep_search': grep_search
        }
    
    async def process_request(self, user_input: str, context: list, working_directory: str) -> str:
        """
        è¿™ä¸ªæ–¹æ³•å·²åºŸå¼ƒ - ç°åœ¨ç”±AIç›´æ¥å¤„ç†è¯·æ±‚
        """
        return "é”™è¯¯ï¼šæ­¤æ–¹æ³•å·²åºŸå¼ƒï¼Œåº”è¯¥ç”±AIç›´æ¥å¤„ç†è¯·æ±‚"


# å¯¼å‡ºå·¥å…·åˆ—è¡¨
ADVANCED_TOOLS = [replace_in_file, str_replace_editor, grep_search]
